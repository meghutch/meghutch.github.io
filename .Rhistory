finalize_workflow(best_glm) %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = True) %>%
arrange(p.value)
# update the workflow and examine the estimated coefficients on the test set
glm_risk_workflow %>%
finalize_workflow(best_glm) %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# update the workflow and examine the estimated coefficients on the test set
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# update the workflow and examine the estimated coefficients on the test set
glm_risk_workflow %>%
finalize_workflow(best_glm) %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
glm_risk_workflow %>%
finalize_workflow(best_glm) %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
fit(train) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
last_fit(train) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# update the workflow and examine the estimated coefficients on the test set
glm_risk_workflow %>%
finalize_workflow(best_glm) %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
fit(train) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
update_best_glm_workflow %>%
last_fit(split_data) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(train) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(train) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value) %>%
View()
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value) %>%
View()
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy(exponentiate = TRUE) %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(test) %>%
extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
exp(-6.89)
table(test$`_STATE`)
table(train$`_STATE`)
79/5000
79/nrow(train)
37/nrow(test)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(test) %>%
# extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
update_best_glm_workflow %>%
fit(test)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
final_test %>%
# extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
#update_best_glm_workflow %>%
final_test %>%
extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
final_test %>%
extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
#
# use the updated workflow to fit to the test set and extract the estimated coefficients
#update_best_glm_workflow %>%
final_test %>%
extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
#update_best_glm_workflow %>%
fit(train) %>%
extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(train) %>%
extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(train) %>%
#extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
update_best_glm_workflow %>%
fit(test) %>%
#extract_fit_parsnip() %>%
tidy() %>%
arrange(p.value)
library(tidyverse)
library(ggplot2)
library(tidymodels)
library(tidyverse)
library(ggplot2)
library(tidymodels)
# load in each data file
data_categorical <- read_csv('data_categorical.csv')
data_numerical <- read_csv('data_numeric.csv')
data_ordinal <- read_csv('data_ordinal.csv')
# evaluate column names
colnames(data_categorical)
colnames(data_numerical)
colnames(data_ordinal)
# create a separate data frame containing only the two DIABETES3 columns
# evaluate if the entries in `DIABETE3...2` and `DIABETE3...20` are identical
cat_diabetes_check <- data_categorical %>%
select(DIABETE3...2, DIABETE3...20) %>%
mutate(is.identical = if_else(DIABETE3...2 == DIABETE3...20, 1, 0))
# evaluate whether there are any rows where `DIABETE3...2` and `DIABETE3...20` are not identical
# if is.identical==0 is TRUE for any row, this means that the columns in at least 1 row are not identical
any(cat_diabetes_check$is.identical == 0)
# create a separate data frame containing only the two MARITAL columns
# evaluate if the entries in `MARITAL...8` and `MARITAL...23` are identical
cat_marital_check <- data_categorical %>%
select(MARITAL...8, MARITAL...23) %>%
mutate(is.identical = if_else(MARITAL...8 == MARITAL...23, 1, 0))
# evaluate whether there are any rows where `MARITAL...8` and `MARITAL...23` are not identical
# if is.identical==0 is TRUE for any row, this means that the columns in at least 1 row are not identical
any(cat_diabetes_check$is.identical == 0)
data_categorical_clean <- data_categorical %>%
select(-DIABETE3...20, -MARITAL...23) %>%
rename(DIABETE3 = "DIABETE3...2",
MARITAL = "MARITAL...8")
# identify whether any columns in `data_numerical` are found in `data_categorical_clean`
shared_columns_cat_numeric <- intersect(names(data_categorical_clean), names(data_numerical))
shared_columns_cat_numeric
# join `data_categorical_clean` and `data_numerical` by the columns that were shared in both datasets
data_cat_numeric <- left_join(data_categorical_clean,
data_numerical,
by = shared_columns_cat_numeric)
# join `data_categorical_clean` and `data_numerical` by the columns that were shared in both datasets
data_cat_numeric <- left_join(data_categorical_clean,
data_numerical,
by = shared_columns_cat_numeric)
# identify whether any columns in `data_ordinal` are found in `data_cat_numeric`
shared_columns_cat_numeric_ordinal <- intersect(names(data_cat_numeric), names(data_ordinal))
shared_columns_cat_numeric_ordinal
data_merged <- left_join(data_cat_numeric,
data_ordinal,
by = shared_columns_cat_numeric_ordinal)
# evaluate dimensions of the dataframe
dim(data_merged)
nrow(data_merged)
# number of the unique patients
nrow(unique(data_merged %>% distinct(PERSONID)))
data_merged <- data_merged %>%
mutate_at(c(colnames(data_categorical_clean)), as.character) %>%
mutate_at(c("NUMADULT", "CHILDREN", "WEIGHT2", "DRVISITS"), as.numeric) %>%
mutate_at(c("GENHLTH" , "_AGEG5YR", "_BMI5CAT", "CHECKUP1", "INCOME2", "_EDUCAG", "SLEPTIM1", "MENTHLTH", "_SMOKER3"), as.character)
# evaluate updates variable types
str(data_merged)
str(data_merged)
table(data_merged$DIABETE3) / nrow(data_merged) * 100
```{r}
table(data_merged$DIABETE3) / nrow(data_merged) * 100
# plot bar graph
ggplot(data_merged,
aes(x = DIABETE3)) +
ylab("Count of Unique Persons") +
geom_bar() +
theme_bw()
ggplot(data_merged,
aes(x = as.integer(`_AGEG5YR`))) +
geom_bar() +
ylab("Count of Unique Persons") +
xlab("_AGEG5YE") +
xlim(0, 14) +
theme_bw()
# evaluate initial summary statistics
summary(data_merged$CHILDREN)
# convert values of 88 to 0
data_merged <- data_merged %>%
mutate(CHILDREN = if_else(CHILDREN == 88, 0, CHILDREN))
table(data_merged$CHILDREN) / nrow(data_merged) * 100
ggplot(data_merged %>%
filter(!CHILDREN == 99),
aes(x = CHILDREN)) +
geom_histogram(bins = 10) +
theme_bw()
# count the number of missing variables by column and arrange by decreasing count
# this step will show us which columns have the highest amount of missingness
colSums(is.na(data_merged)) %>% sort(decreasing = TRUE)
# evaluate initial summary statistics
summary(data_merged$CHILDREN)
# convert values of 88 to 0
data_merged <- data_merged %>%
mutate(CHILDREN = if_else(CHILDREN == 88, 0, CHILDREN))
# recode missing data
data_merged <- data_merged %>%
mutate(MSCODE = ifelse(is.na(MSCODE), 6, MSCODE), # add a value of 6 to represent: GU, PR, VI
FLUSHOT6 = ifelse(is.na(FLUSHOT6), 3, FLUSHOT6), # add a value of 3 to represent the patient is age < 65, and thus this column is not relevant
# create a category to represent missingness for categorical variables
HLTHCVR1 = ifelse(is.na(HLTHCVR1), 999, HLTHCVR1),
`_BMI5CAT` = ifelse(is.na(`_BMI5CAT`), 999, `_BMI5CAT`),
DECIDE = ifelse(is.na(DECIDE), 999, DECIDE),
BLIND = ifelse(is.na(BLIND), 999, BLIND),
USEEQUIP = ifelse(is.na(USEEQUIP), 999, USEEQUIP),
RENTHOM1 = ifelse(is.na(RENTHOM1), 999, RENTHOM1),
INCOME2 = ifelse(is.na(INCOME2), 999, INCOME2),
EMPLOY1 = ifelse(is.na(EMPLOY1), 999, EMPLOY1),
MARITAL = ifelse(is.na(MARITAL), 999, MARITAL),
`_RACE` = ifelse(is.na(`_RACE`), 999, `_RACE`),
)
# count the number of missing variables by column and arrange by decreasing count
# this step will show us which columns have the highest amount of missingness
colSums(is.na(data_merged)) %>% sort(decreasing = TRUE)
data_merged <- data_merged %>%
# create a temporary new variable
# '.' represents the first character (in our case '9')
mutate(kg = ifelse(WEIGHT2 >= 9000 & WEIGHT2 <= 9998, 1, 0),
WEIGHT2_new = ifelse(WEIGHT2 >= 9000 & WEIGHT2 <= 9998, sub(".", "", WEIGHT2), WEIGHT2),
WEIGHT2_new = sub("^0+", "", WEIGHT2_new),
WEIGHT2_new = ifelse(WEIGHT2_new == 7777 | WEIGHT2_new == 9999, NA, WEIGHT2_new),
WEIGHT2_new = as.numeric(WEIGHT2_new),
WEIGHT2_kg  = if_else(kg == 0, WEIGHT2_new * 0.453592, WEIGHT2_new))
# evaluate range of pounds
lbs_check <- data_merged %>%
filter(kg == 0)
summary(lbs_check$WEIGHT2_new)
summary(data_merged$WEIGHT2_kg)
# create binary indicator of diabetes status (`DIABETE3_y`)
# This will remove 7 persons who did not answer or know if they had diabetes
# a person will
data_merged_model <- data_merged %>%
filter(DIABETE3 %in% c(1, 2, 3, 4)) %>%
mutate(DIABETE3_y = if_else(DIABETE3 %in% c(1,2), 1, 0),
DIABETE3_y = as.factor(DIABETE3_y))
data_merged_model_clean <- data_merged_model %>%
select(DIABETE3_y, everything(), -PERSONID, -DIABETE3, -NUMADULT, -DRVISITS, -WEIGHT2, -WEIGHT2_new, -kg)
colSums(is.na(data_merged_model_clean)) %>% sort(decreasing = TRUE)
# evaluate proportion of missingness
colSums(is.na(data_merged_model_clean)) %>% sort(decreasing = TRUE)
colSums(is.na(data_merged_model_clean)) %>% sort(decreasing = TRUE)
# drop ~200 rows with misisng
data_merged_model_clean <- data_merged_model_clean %>%
na.omit()
nrow(data_merged_model_clean)
# set seed for reproducibility
set.seed(1250)
# initialize training and test splits
split_data <- initial_split(data_merged_model_clean, strata = DIABETE3_y, prop = 0.75)
# use the tidymodels package to create our training() and testing() datasets
train <- training(split_data)
test  <- testing(split_data)
# define "recipe" to indicate the logistic regression formula
glm_recipe <- recipe(DIABETE3_y ~ ., data = train)
# indicate the number of folds for cross-fold validation
folds <- vfold_cv(train, v = 5)
# initialize a logistic regression classification model
risk_model <-
logistic_reg(mode = "classification") %>%
set_engine("glm")
# specify tidymodels workflow for running our classifier
glm_risk_workflow <-
workflow() %>%
add_model(risk_model) %>%
add_recipe(glm_recipe)
risk_model_train <-
glm_risk_workflow %>%
tune_grid(folds,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc, accuracy, sensitivity, specificity))
collect_metrics(risk_model_train)
# identify the best fit model during cross-fold validation
# we will determine the best model using the area under the receiver operator curve (roc_auc)
best_fit <- risk_model_train %>%
select_best(metric = "roc_auc")
# update the workflow with the best_fit
update_best_glm_workflow <-
glm_risk_workflow %>%
finalize_workflow(best_fit)
final_test <-
update_best_glm_workflow %>%
last_fit(split_data)
# identify the best fit model during cross-fold validation
# we will determine the best model using the area under the receiver operator curve (roc_auc)
best_fit <- risk_model_train %>%
select_best(metric = "roc_auc")
# update the workflow with the best_fit
update_best_glm_workflow <-
glm_risk_workflow %>%
finalize_workflow(best_fit)
final_test <-
update_best_glm_workflow %>%
last_fit(split_data)
```{r}
final_test %>%
collect_metrics()
risk_model_train <-
glm_risk_workflow %>%
tune_grid(folds,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc, accuracy))
collect_metrics(risk_model_train)
collect_metrics(risk_model_train)
# identify the best fit model during cross-fold validation
# we will determine the best model using the area under the receiver operator curve (roc_auc)
best_fit <- risk_model_train %>%
select_best(metric = "roc_auc")
# update the workflow with the best_fit
update_best_glm_workflow <-
glm_risk_workflow %>%
finalize_workflow(best_fit)
final_test <-
update_best_glm_workflow %>%
last_fit(split_data)
final_test %>%
collect_metrics()
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
arrange(p.value)
table(test$DIABETE3_y, test$`_STATE`)
table(test$`_STATE`)
table(data_merged_model_clean$DIABETE3_y, data_merged_model_clean$`_STATE`)
table(data_merged_model_clean$DIABETE3_y, data_merged_model_clean$GENHLTH5)
table(data_merged_model_clean$DIABETE3_y, data_merged_model_clean$GENHLTH)
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
arrange(desc(estimate))
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
arrange(p.value) %>%
filter(p.value <= 0.10)
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
filter(p.value <= 0.05) %>%
arrange(desc(estimate))
table(data_merged$DIABETE3)
# create binary indicator of diabetes status (`DIABETE3_y`)
# This will remove 7 persons who did not answer or know if they had diabetes
# a person will
data_merged_model <- data_merged %>%
filter(DIABETE3 %in% c(1, 2, 3, 4)) %>%
mutate(DIABETE3_y = if_else(DIABETE3 == 1, 1, 0),
DIABETE3_y = as.factor(DIABETE3_y))
# identify variables to keep and remove
data_merged_model_clean <- data_merged_model %>%
select(DIABETE3_y, everything(), -PERSONID, -DIABETE3, -NUMADULT, -DRVISITS, -WEIGHT2, -WEIGHT2_new, -kg)
# evaluate proportion of missingness
colSums(is.na(data_merged_model_clean)) %>% sort(decreasing = TRUE)
# drop ~200 rows with misisng
data_merged_model_clean <- data_merged_model_clean %>%
na.omit()
nrow(data_merged_model_clean)
# set seed for reproducibility
set.seed(1250)
# initialize training and test splits
split_data <- initial_split(data_merged_model_clean, strata = DIABETE3_y, prop = 0.75)
# use the tidymodels package to create our training() and testing() datasets
train <- training(split_data)
test  <- testing(split_data)
risk_model_train <-
glm_risk_workflow %>%
tune_grid(folds,
control = control_grid(save_pred = TRUE),
metrics = metric_set(roc_auc, accuracy))
collect_metrics(risk_model_train)
# identify the best fit model during cross-fold validation
# we will determine the best model using the area under the receiver operator curve (roc_auc)
best_fit <- risk_model_train %>%
select_best(metric = "roc_auc")
# update the workflow with the best_fit
update_best_glm_workflow <-
glm_risk_workflow %>%
finalize_workflow(best_fit)
final_test <-
update_best_glm_workflow %>%
last_fit(split_data)
final_test %>%
collect_metrics()
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
filter(p.value <= 0.05) %>%
arrange(desc(estimate))
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
arrange(desc(p.value))
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
arrange(p.value)
table(test$DIABETE3_y, test$GENHLTH)
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(train) %>%
tidy() %>%
arrange(p.value)
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
arrange(p.value)
filter(p.value <= 0.05) %>%
arrange(desc(estimate))
filter(p.value <= 0.05) %>%
arrange(desc(estimate))
# use the updated workflow to fit to the test set and extract the estimated coefficients
# arrange by lowest p-value
update_best_glm_workflow %>%
fit(test) %>%
tidy() %>%
filter(p.value <= 0.05) %>%
arrange(desc(estimate))
exp(3.6642431)
setwd("~/Projects/meghutch.github.io")
